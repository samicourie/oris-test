{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c0c98-9f12-485d-b209-829454f57510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oris data scientist test\n",
    "\n",
    "# Requirement for the code to run\n",
    "# Using python 3.12.3, run the following commands\n",
    "pip install numpy\n",
    "pip install pandas\n",
    "pip install -U scikit-learn\n",
    "pip install tensorflow\n",
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52c3c5f-0df3-48ca-a54f-a8dfb81cd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow for image feature extraction and scikit-learn for classification.\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_input_vgg\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4902d-69c0-4a50-9670-72f2654cbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I chose both VGG16 and ResNet50 since (from my understanding) they showed recently good results for image classification\n",
    "# as a feature extractions algorithms, while VGG16 is a bit old, it could be used as a benchmark for comparing results later on\n",
    "# with new algorithms such as ResNet50.\n",
    "\n",
    "# The rest of the parameters such as image size (224, 224) and batch_size, I used what the general consensus agrees on \n",
    "# when dealing with image classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "13403444-3b13-4822-afd7-a19691796ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpopse of this class to have the ability to choose from different keras models\n",
    "# or different classification models, here I have added VGG16 and ResNet50, but we can imagine\n",
    "# adding later VGG19 or some other models, same goes for classification methods.\n",
    "\n",
    "class QuarryClassifier:\n",
    "    def __init__(self, base_model='vgg', clf='rf', batch_size=32, fine_tune_flag=False):\n",
    "\n",
    "        if base_model is None or base_model == 'vgg':\n",
    "            self.base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "            self.preprocessor = preprocess_input_vgg\n",
    "        else:\n",
    "            self.base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "            self.preprocessor = preprocess_input_resnet\n",
    "        self.model = self.base_model\n",
    "\n",
    "        if clf is None or clf == 'rf':\n",
    "            self.clf = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=2)\n",
    "        else:\n",
    "            self.clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=2, random_state=42)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.fine_tune_flag = fine_tune_flag\n",
    "\n",
    "    def load_and_preprocess_image(self, image_paths, preprocess_input):\n",
    "        # Load and transform an image to a numpy array of size (224, 224)\n",
    "        batch_images = []\n",
    "        for path in image_paths:\n",
    "            img = load_img(path, target_size=(224, 224))\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            batch_images.append(img_array)\n",
    "        return np.array(batch_images)\n",
    "\n",
    "    def extract_features(self, image_paths):\n",
    "        # Batch image loading and feature extraction.\n",
    "        n_samples_train = len(image_paths)\n",
    "\n",
    "        image_data = []\n",
    "\n",
    "        for i in range(0, n_samples_train, self.batch_size):\n",
    "            train_image_batch = self.load_and_preprocess_image(image_paths.iloc[i:i+self.batch_size], self.preprocessor)\n",
    "            if not self.fine_tune_flag:\n",
    "                train_image_batch = self.base_model.predict(train_image_batch)\n",
    "            image_data.append(train_image_batch)\n",
    "\n",
    "        image_data = np.vstack(image_data)\n",
    "        if not self.fine_tune_flag:\n",
    "            image_data = image_data.reshape(image_data.shape[0], -1)\n",
    "        return image_data\n",
    "\n",
    "    def save_features(self, features_data, file_name='train.npy'):\n",
    "        with open(file_name, 'wb') as file:\n",
    "            np.save(file, features_data)\n",
    "\n",
    "    def fit_classifier(self, features_data, y_train):\n",
    "        # Fit a classifier using the extracted features from images.\n",
    "        self.clf.fit(features_data, y_train)\n",
    "\n",
    "    def predict_classifier(self, features_test_data):\n",
    "        # Predict new image data using a classification method like RF or GBT.\n",
    "        y_pred = self.clf.predict(features_test_data)\n",
    "        return y_pred\n",
    "\n",
    "    def build_fine_tune_model(self, base_model, num_classes=2):\n",
    "        # For tuning purposed, build the different layers of the chosen model.\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False  # Freeze the convolutional base\n",
    "\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "\n",
    "        # For prediction purposes.\n",
    "        predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "        fine_tune_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        return fine_tune_model\n",
    "\n",
    "    def compile_fine_tune_models(self):\n",
    "        self.model = self.build_fine_tune_model(self.base_model)\n",
    "        self.model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def fine_tune(self, image_path, labels, val_split_rate=0.2, epochs=20, model_name='fine_tuned.keras'):\n",
    "        # Fine tune a keras model using different available options like validation rate and number of epochs.\n",
    "        train_images = self.extract_features(image_path)\n",
    "        datagen = ImageDataGenerator(validation_split=val_split_rate)\n",
    "\n",
    "        train_generator = datagen.flow(train_images, to_categorical(labels), batch_size=self.batch_size, subset='training')\n",
    "        validation_generator = datagen.flow(train_images, to_categorical(labels), batch_size=self.batch_size, subset='validation')\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "                     ModelCheckpoint(model_name, save_best_only=True)]\n",
    "\n",
    "        self.model.fit(train_generator, validation_data=validation_generator, epochs=epochs, callbacks=callbacks)\n",
    "\n",
    "    def save_model(self, model_name):\n",
    "        self.model.save(model_name)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        self.model = load_model(model_name)\n",
    "    \n",
    "    def load_fine_tune_model_weights(self, model_name):\n",
    "        self.model.load_weights(model_name)\n",
    "\n",
    "    def predict(self, test_images):\n",
    "        return self.model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c07ef792-c984-4bed-942a-0a56a0ef5324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               site_name  company_name  \\\n",
      "0       Carrières Daniel           NaN   \n",
      "1         Malet Horgues.           NaN   \n",
      "2          Carrieres Plo           NaN   \n",
      "3  Dastugue Jean et Fils           NaN   \n",
      "4  Pema Carrières Du Roc           NaN   \n",
      "\n",
      "                                                link  latitude  longitude  \\\n",
      "0  https://www.google.com/maps/place/Carri%C3%A8r...   43.0477    -0.0473   \n",
      "1  https://www.google.com/maps/place/Malet+Horgue...   43.1903     0.0916   \n",
      "2  https://www.google.com/maps/place/Carrieres+Pl...   42.9605     0.3937   \n",
      "3  https://www.google.com/maps/place/Dastugue+Jea...   43.0689     0.3865   \n",
      "4  https://www.google.com/maps/place/Pema+Carri%C...   43.6493     0.3439   \n",
      "\n",
      "                                             address homepage    phone  \\\n",
      "0                      Le Village, 65100 Ger, France      NaN  #ERROR!   \n",
      "1             Chem. de Mansas, 65310 Horgues, France      NaN      NaN   \n",
      "2                       Village, 65410 Ilhet, France      NaN  #ERROR!   \n",
      "3  Rue du Bas Mour, 65250 La Barthe-de-Neste, France      NaN  #ERROR!   \n",
      "4                             32320 Riguepeu, France      NaN  #ERROR!   \n",
      "\n",
      "   sales_phone  email  sales_email opening_hours site_type  \\\n",
      "0          NaN    NaN          NaN           NaN    Quarry   \n",
      "1          NaN    NaN          NaN           NaN    Quarry   \n",
      "2          NaN    NaN          NaN           NaN    Quarry   \n",
      "3          NaN    NaN          NaN           NaN    Quarry   \n",
      "4          NaN    NaN          NaN           NaN    Quarry   \n",
      "\n",
      "                                     id  \\\n",
      "0  949a5a8b-8e9d-40c5-8100-2f30a3e82f7b   \n",
      "1  044d1092-4bb7-4e09-b073-113037a0a196   \n",
      "2  738e1bd8-6a64-40a9-85ff-c442965db618   \n",
      "3  1e07b5a8-b697-4971-bc39-b57d05084eea   \n",
      "4  e96a46a3-9be3-4d3d-a3ec-2563c0e13ef2   \n",
      "\n",
      "                                          image_path  \n",
      "0  data/images/train/949a5a8b-8e9d-40c5-8100-2f30...  \n",
      "1  data/images/train/044d1092-4bb7-4e09-b073-1130...  \n",
      "2  data/images/train/738e1bd8-6a64-40a9-85ff-c442...  \n",
      "3  data/images/train/1e07b5a8-b697-4971-bc39-b57d...  \n",
      "4  data/images/train/e96a46a3-9be3-4d3d-a3ec-2563...  \n",
      "site_name           0\n",
      "company_name     1039\n",
      "link                0\n",
      "latitude            0\n",
      "longitude           0\n",
      "address             6\n",
      "homepage          627\n",
      "phone             241\n",
      "sales_phone      1039\n",
      "email            1039\n",
      "sales_email      1039\n",
      "opening_hours     525\n",
      "site_type           0\n",
      "id                  0\n",
      "image_path          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "\n",
    "train_data = pd.read_csv('data/X_train.csv')\n",
    "test_data = pd.read_csv('data/X_test.csv')\n",
    "y_train = pd.read_csv('data/Y_train.csv')['output'].values\n",
    "y_test = pd.read_csv('data/Y_test.csv')['output'].values\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(train_data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "##############################################################################################\n",
    "# In this test, I only used the images to predict whether an image is a quarry or not,\n",
    "# we can imagine using different availabe features but stacking the image features with latitude, longitude and site_type,\n",
    "# then fit and train a random forest or any other binary classification model.\n",
    "##############################################################################################\n",
    "\n",
    "# train_structured_data = self.train_data[['latitude', 'longitude', 'site_type']].values\n",
    "# test_structured_data = self.test_data[['latitude', 'longitude', 'site_type']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93bf84-ef7e-4d46-a607-1c969f344fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also we can infer from the calculating the null data, that 'company_name', 'homepage', 'phone', \n",
    "# 'sales_phone', 'email', 'sales_email', 'opening_hours' are not important due to a high number of null values.\n",
    "# 'site_type' is almost identical, so it can also be dropped.\n",
    "# But for the sake of simplicity, I didn't use any feature other than the image itself for training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d1b42-649f-46c0-873b-e17f9b7496c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: By using the base keras model to extact image features with no FINE TUNING \n",
    "# and a then predict using standard classifier\n",
    "\n",
    "fine_tune_flag = False \n",
    "classifier = QuarryClassifier(base_model='resnet50', clf='rf', fine_tune_flag=fine_tune_flag)\n",
    "\n",
    "train_features = classifier.extract_features(train_data['image_path'])\n",
    "test_features = classifier.extract_features(test_data['image_path'])\n",
    "\n",
    "# Saving the features for futur use and better inference time.\n",
    "classifier.save_features(train_features, file_name='base_resnet_train.npy')\n",
    "classifier.save_features(test_features, file_name='base_resnet_test.npy')\n",
    "\n",
    "start_time = time.time()\n",
    "# With a random forest or a gbt classifier\n",
    "classifier.fit_classifier(train_features, y_train)\n",
    "y_pred = classifier.predict_classifier(test_features)\n",
    "end_time = time.time()\n",
    "print('Ensemble classifier model report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Inference time with an ensemble method:', str(round(end_time - start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3893f228-b0a5-4a3f-bd94-873baf681b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: By FINE TUNING the base model and use it for prediction\n",
    "fine_tune_flag = True \n",
    "classifier = QuarryClassifier(base_model='resnet50', fine_tune_flag=fine_tune_flag)\n",
    "classifier.compile_fine_tune_models()\n",
    "classifier.fine_tune(train_data['image_path'], y_train, val_split_rate=0.2, epochs=10, model_name='resnet_tuned_weights_ep10.keras')\n",
    "\n",
    "start_time = time.time()\n",
    "test_features = classifier.extract_features(test_data['image_path'])\n",
    "classifier.save_features(test_features, file_name='tuned_resnet_test.npy')\n",
    "y_pred = classifier.predict(test_features)\n",
    "end_time = time.time()\n",
    "print(classification_report(y_test, np.argmax(y_pred, axis=1)))\n",
    "print('Inference Time:', str(round(end_time - start_time, 2)))\n",
    "\n",
    "classifier.save_model('resnet_tuned_10e.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77ef251d-4457-4d97-9bb3-fdea83a11c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble classifier model report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.49      0.49       256\n",
      "           1       0.51      0.50      0.50       269\n",
      "\n",
      "    accuracy                           0.50       525\n",
      "   macro avg       0.50      0.50      0.50       525\n",
      "weighted avg       0.50      0.50      0.50       525\n",
      "\n",
      "Inference time with an ensemble method: 4.29\n"
     ]
    }
   ],
   "source": [
    "# OPTION 3: Read previously generated image features for training and prediction and better inference time\n",
    "classifier = QuarryClassifier(base_model='resnet50', clf='rf', fine_tune_flag=False)\n",
    "\n",
    "with open('base_resnet_train.npy', 'rb') as file:\n",
    "   train_features = np.load(file)\n",
    "with open('base_resnet_test.npy', 'rb') as file:\n",
    "   test_features = np.load(file)\n",
    "\n",
    "start_time = time.time()\n",
    "# With a random forest or a gbt classifier\n",
    "classifier.fit_classifier(train_features, y_train)\n",
    "y_pred = classifier.predict_classifier(test_features)\n",
    "end_time = time.time()\n",
    "print('Ensemble classifier model report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Inference time with an ensemble method:', str(round(end_time - start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3d995a2e-19ee-4518-b139-542f18626493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.58      0.53       256\n",
      "           1       0.52      0.43      0.47       269\n",
      "\n",
      "    accuracy                           0.50       525\n",
      "   macro avg       0.50      0.50      0.50       525\n",
      "weighted avg       0.50      0.50      0.50       525\n",
      "\n",
      "Inference Time: 32.14\n"
     ]
    }
   ],
   "source": [
    "# OPTION 4: Load previously tuned model for prediction purposes.\n",
    "classifier = QuarryClassifier(base_model='restnet50')\n",
    "classifier.load_model('resnet_tuned_e10.keras')\n",
    "with open('tuned_resnet_test.npy', 'rb') as file:\n",
    "   test_features = np.load(file)\n",
    "start_time = time.time()\n",
    "y_pred = classifier.predict(test_features)\n",
    "end_time = time.time()\n",
    "print(classification_report(y_test, np.argmax(y_pred, axis=1)))\n",
    "print('Inference Time:', str(round(end_time - start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750a167-36e0-40ca-8f74-9133f018320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhancement\n",
    "# 1) Results could be improved by using the rest of the features like 'latitude', 'longitude' and 'site_type'\n",
    "# 2) No paramter tuning was done which gived a room for improvement by trying different parameters values,\n",
    "# parameters such as number of epochs and validation rate, or by using cross validation for better insight of the results.\n",
    "\n",
    "# 3) Same goes for the classifier, we can try with different number of trees or max depth depending on the algorithm.\n",
    "\n",
    "# 4) I don't have much experience with image processing algorithms, more in-depth knowledge about the algorithms\n",
    "# could give place for better understanding and better results, e.g. using segmentation algorithms instead of feature extraction.\n",
    "\n",
    "# 5) Inference time could still be improved by saving the classifier model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
